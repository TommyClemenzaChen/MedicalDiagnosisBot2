{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960\n",
      "240, (240, 3))\n",
      "Unnamed: 0\n",
      "label\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "data = pd.read_csv('Symptom2Disease.csv')\n",
    "\n",
    "#split data into train and test\n",
    "train_data = data.sample(frac=0.8, random_state=0)\n",
    "test_data = data.drop(train_data.index)\n",
    "\n",
    "print(len(train_data))\n",
    "print(f\"{len(test_data)}, {test_data.shape})\")\n",
    "\n",
    "for i,x in enumerate(test_data):\n",
    "    if(i == 10):\n",
    "        break\n",
    "    print(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#connect to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "train_labels = train_data['label'].values\n",
    "train_text = train_data['text'].values\n",
    "\n",
    "#test data\n",
    "test_labels = test_data['label'].values\n",
    "test_text = test_data['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  I have seen rashes on my arms and neck and it itches if I scratch them. I've also had a high fever for a few days. I have no idea what is causing it. The itching is causing me a lot of discomforts.\n",
      "Token IDs: tensor([  101,  1045,  2031,  2464, 23438])\n"
     ]
    }
   ],
   "source": [
    "#tokenize data\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "#tokenize and convert each sentence into tensors\n",
    "input_ids = []\n",
    "for sent in train_text:\n",
    "\n",
    "    encoded_sent = tokenizer.encode(sent,add_special_tokens = True)\n",
    "    input_ids.append(torch.tensor(encoded_sent))\n",
    "    \n",
    "\n",
    "test_input_ids = []\n",
    "for sent in test_text:\n",
    "        encoded_sent = tokenizer.encode(sent,add_special_tokens = True)\n",
    "        test_input_ids.append(torch.tensor(encoded_sent))\n",
    "\n",
    "#tokenize and convert each sentence into tensors\n",
    "label_ids = []\n",
    "for label in train_labels:\n",
    "    \n",
    "    encoded = tokenizer.encode(label,add_special_tokens = True)\n",
    "    label_ids.append(torch.tensor(encoded))\n",
    "\n",
    "test_label_ids = []\n",
    "for label in test_labels:\n",
    "    encoded = tokenizer.encode(label,add_special_tokens = True)\n",
    "    test_label_ids.append(torch.tensor(encoded))\n",
    "\n",
    "\n",
    "print('Original: ', train_text[0])\n",
    "print('Token IDs:', input_ids[0][0:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([960, 78])\n",
      "torch.Size([240, 78])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "#pad the tensors to make them of equal length\n",
    "padded_input_ids = pad_sequence(input_ids, batch_first=True) #78 size\n",
    "testing = pad_sequence(test_input_ids, batch_first=True)  #68 size\n",
    "\n",
    "#pad them so they are the same size\n",
    "padded_test_input_ids = torch.nn.functional.pad(testing, (0, 78 - testing.size(1)), value=0)\n",
    "\n",
    "print(padded_input_ids.shape)\n",
    "print(padded_test_input_ids.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pad the tensors to make them of equal length\n",
    "padded_labels = pad_sequence(label_ids, batch_first=True)\n",
    "padded_test_labels = pad_sequence(test_label_ids, batch_first=True, padding_value = 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([960, 78])\n",
      "input_size: 78, output_size: 12, hidden_size: 50\n",
      "input_size1: 78, output_size1: 12, hidden_size: 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "input_size = padded_input_ids.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = padded_labels.shape[1]\n",
    "\n",
    "input_size1 = padded_test_input_ids.shape[1]\n",
    "hidden_size = 50\n",
    "output_size1 = padded_test_labels.shape[1]\n",
    "\n",
    "print(padded_input_ids.shape)\n",
    "\n",
    "print(f\"input_size: {input_size}, output_size: {output_size}, hidden_size: {hidden_size}\")\n",
    "print(f\"input_size1: {input_size1}, output_size1: {output_size1}, hidden_size: {hidden_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a simple fnn model that takes in the input size\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    \n",
    "#rnn model\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    \n",
    "#LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    def predict(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "960\n"
     ]
    }
   ],
   "source": [
    "#define hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 1\n",
    "\n",
    "print(input_size)\n",
    "seq_len_train = padded_input_ids.size(0)\n",
    "seq_len_test = padded_test_input_ids.size(0)\n",
    "seq_len_train1 = padded_labels.size(0)\n",
    "seq_len_test1 = padded_test_labels.size(0)\n",
    "\n",
    "\n",
    "\n",
    "print(seq_len_train)\n",
    "\n",
    "\n",
    "#seq len == input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 960, 78])\n",
      "torch.Size([1, 240, 78])\n",
      "torch.Size([1, 960, 12])\n",
      "torch.Size([1, 240, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): RNN(78, 50, batch_first=True)\n",
       "  (fc): Linear(in_features=50, out_features=12, bias=True)\n",
       "  (softmax): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_num = 1\n",
    "model = None\n",
    "if(model_num == 0):\n",
    "    model = FNN(input_size, hidden_size, output_size)\n",
    "\n",
    "elif(model_num == 1):\n",
    "    #Reshape for RNN\n",
    "    padded_input_ids = padded_input_ids.reshape(1, seq_len_train, input_size)\n",
    "    padded_test_input_ids = padded_test_input_ids.reshape(1, seq_len_test, input_size1)\n",
    "    padded_labels = padded_labels.reshape(1, seq_len_train1, output_size)\n",
    "    padded_test_labels = padded_test_labels.reshape(1, seq_len_test1, output_size1)\n",
    "    \n",
    "    print(padded_input_ids.shape)\n",
    "    print(padded_test_input_ids.shape)\n",
    "    print(padded_labels.shape)\n",
    "    print(padded_test_labels.shape)\n",
    "    \n",
    "    model = RNN(input_size, hidden_size, output_size)\n",
    "\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1045,  2031,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  2026, 10063,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2067,  3255,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  2031,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[  101,  7975, 13433,  ...,     0,     0,     0],\n",
      "        [  101, 28079,  8985,  ...,     0,     0,     0],\n",
      "        [  101,  8827, 11069,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 28711, 11867,  ...,     0,     0,     0],\n",
      "        [  101,  8827, 11069,  ...,     0,     0,     0],\n",
      "        [  101, 28711, 11867,  ...,     0,     0,     0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bobth\\Downloads\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 960, 12])) that is different to the input size (torch.Size([1, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [20/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [30/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [40/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [50/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [60/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [70/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [80/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [90/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [100/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [110/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [120/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [130/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [140/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [150/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [160/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [170/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [180/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [190/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [200/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [210/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [220/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [230/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [240/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [250/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [260/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [270/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [280/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [290/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [300/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [310/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [320/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [330/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [340/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [350/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [360/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [370/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [380/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [390/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [400/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [410/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [420/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [430/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [440/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [450/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [460/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [470/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [480/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [490/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [500/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [510/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [520/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [530/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [540/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [550/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [560/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [570/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [580/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [590/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [600/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [610/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [620/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [630/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [640/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [650/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [660/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [670/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [680/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [690/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [700/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [710/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [720/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [730/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [740/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [750/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [760/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [770/960], Loss: 61041380.0000\n",
      "Epoch [1/10], Step [780/960], Loss: 61041380.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[226], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     14\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\bobth\\Downloads\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bobth\\Downloads\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "#train the model\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, seq_len_train):\n",
    "        inputs = padded_input_ids.to(device)\n",
    "        labels = padded_labels.to(device)\n",
    "        if(i == 0):\n",
    "            print(inputs[0])\n",
    "            print(labels[0])\n",
    "        \n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{seq_len_train}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 240 test images: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "#test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(0, seq_len_test):\n",
    "        inputs = padded_test_input_ids.to(device)\n",
    "        labels = padded_test_labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, actual = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == actual).sum().item()\n",
    "        \n",
    "    print(f'Accuracy of the network on the {total} test images: {100 * correct / total} %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 240 test images: 100.0 %\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[225], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m [y_pred, y_true] \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mcat(y_pred, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), torch\u001b[39m.\u001b[39mcat(y_true, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()]\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mAccuracy of the network on the \u001b[39m\u001b[39m{\u001b[39;00mtotal\u001b[39m}\u001b[39;00m\u001b[39m test images: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39mcorrect\u001b[39m \u001b[39m\u001b[39m/\u001b[39m\u001b[39m \u001b[39mtotal\u001b[39m}\u001b[39;00m\u001b[39m %\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1 score: \u001b[39m\u001b[39m{\u001b[39;00mf1_score(y_true,\u001b[39m \u001b[39;49my_pred,\u001b[39m \u001b[39;49maverage\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprecision score: \u001b[39m\u001b[39m{\u001b[39;00mprecision_score(y_true,\u001b[39m \u001b[39my_pred,\u001b[39m \u001b[39maverage\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecall score: \u001b[39m\u001b[39m{\u001b[39;00mrecall_score(y_true,\u001b[39m \u001b[39my_pred,\u001b[39m \u001b[39maverage\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bobth\\Downloads\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1011\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[0;32m   1012\u001b[0m     y_true,\n\u001b[0;32m   1013\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1020\u001b[0m ):\n\u001b[0;32m   1021\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \n\u001b[0;32m   1023\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[0;32m   1147\u001b[0m         y_true,\n\u001b[0;32m   1148\u001b[0m         y_pred,\n\u001b[0;32m   1149\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1150\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1151\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1152\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1153\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1154\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1155\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bobth\\Downloads\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[0;32m   1159\u001b[0m     y_true,\n\u001b[0;32m   1160\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1168\u001b[0m ):\n\u001b[0;32m   1169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \n\u001b[0;32m   1171\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1284\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1288\u001b[0m         y_true,\n\u001b[0;32m   1289\u001b[0m         y_pred,\n\u001b[0;32m   1290\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[0;32m   1291\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1292\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1293\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1294\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1295\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1296\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1297\u001b[0m     )\n\u001b[0;32m   1298\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\bobth\\Downloads\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bobth\\Downloads\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1372\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\bobth\\Downloads\\lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "#f1score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for i in range(0, seq_len_test):\n",
    "        inputs = padded_test_input_ids.to(device)\n",
    "        labels = padded_test_labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, actual = torch.max(labels.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == actual).sum().item()\n",
    "        y_pred.append(predicted)\n",
    "        y_true.append(actual)\n",
    "    \n",
    "    #[y_pred, y_true] = [torch.cat(y_pred, dim=0).cpu().numpy(), torch.cat(y_true, dim=0).cpu().numpy()]\n",
    "\n",
    "    print(y_pred)\n",
    "    print(f'Accuracy of the network on the {total} test images: {100 * correct / total} %')\n",
    "    print(f'f1 score: {f1_score(y_true, y_pred, average=\"macro\")}')\n",
    "    print(f'precision score: {precision_score(y_true, y_pred, average=\"macro\")}')\n",
    "    print(f'recall score: {recall_score(y_true, y_pred, average=\"macro\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
